{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_analysis_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufZ_GyWhBWg3",
        "outputId": "bd34287b-72a8-4772-c31b-e7f8595b1038"
      },
      "source": [
        "#downloading downgraded version of numpy \n",
        "!pip install numpy==1.16.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy==1.16.1 in /usr/local/lib/python3.7/dist-packages (1.16.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FqvYBiMB7oU"
      },
      "source": [
        " #importing important Libraries\n",
        " import numpy\n",
        " from numpy import array\n",
        " import keras\n",
        " from keras.datasets import imdb\n",
        " from keras.layers import Dense\n",
        " from keras.layers import LSTM,Dropout\n",
        " from keras.layers.embeddings import Embedding\n",
        " from keras.models import load_model\n",
        " from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        " import re\n",
        " import numpy as np\n",
        " from nltk.tokenize import word_tokenize\n",
        " import nltk\n",
        "\n",
        " #fixing random seed\n",
        " numpy.random.seed(1)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GuSvYq9C-G2",
        "outputId": "8bfb4f66-8ced-409f-a44e-274f749e0065"
      },
      "source": [
        "top_words =5000\n",
        "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words=top_words)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvF_XaYyDmad",
        "outputId": "c32e1cbc-b0ed-4667-f02d-fa018ca9303f"
      },
      "source": [
        "\"\"\"inspecting a sample review and its label\n",
        "note:- the review are stored as a sequence of integers ,these have been pre-asigned\n",
        "to individual words and the label as interger(0=negative , 1=positive) \"\"\"\n",
        "print(\"*****Reviews*****\")\n",
        "print(X_train[6])\n",
        "print(\"*****Label*****\")\n",
        "print(y_train[6])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*****Reviews*****\n",
            "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
            "*****Label*****\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj8h1Kk9Egj7",
        "outputId": "17880f21-8c98-44fd-ab19-aeca2e3a96b3"
      },
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word={i:word for word, i in word2id.items()}\n",
        "print(\"*****Reviews with words*****\")\n",
        "print([id2word.get(i,' ')for  i in X_train[6]])\n",
        "print(\"*****Label*****\")\n",
        "print(y_train[6])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n",
            "*****Reviews with words*****\n",
            "['the', 'and', 'full', 'involving', 'to', 'impressive', 'boring', 'this', 'as', 'and', 'and', 'br', 'villain', 'and', 'and', 'need', 'has', 'of', 'costumes', 'b', 'message', 'to', 'may', 'of', 'props', 'this', 'and', 'and', 'concept', 'issue', 'and', 'to', \"god's\", 'he', 'is', 'and', 'unfolds', 'movie', 'women', 'like', \"isn't\", 'surely', \"i'm\", 'and', 'to', 'toward', 'in', \"here's\", 'for', 'from', 'did', 'having', 'because', 'very', 'quality', 'it', 'is', 'and', 'and', 'really', 'book', 'is', 'both', 'too', 'worked', 'carl', 'of', 'and', 'br', 'of', 'reviewer', 'closer', 'figure', 'really', 'there', 'will', 'and', 'things', 'is', 'far', 'this', 'make', 'mistakes', 'and', 'was', \"couldn't\", 'of', 'few', 'br', 'of', 'you', 'to', \"don't\", 'female', 'than', 'place', 'she', 'to', 'was', 'between', 'that', 'nothing', 'and', 'movies', 'get', 'are', 'and', 'br', 'yes', 'female', 'just', 'its', 'because', 'many', 'br', 'of', 'overly', 'to', 'descent', 'people', 'time', 'very', 'bland']\n",
            "*****Label*****\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWqzxB2gGJ3r",
        "outputId": "d5c77bc7-2a17-4b77-ba76-e2d82a14dfa1"
      },
      "source": [
        "#maximum and minimum review length\n",
        "print('Maximum review length :{}'.format(\n",
        "    len(max((X_train + X_test),key=len))))\n",
        "print('Minimum review length :{}'.format(\n",
        "    len(min((X_train + X_test),key=len))))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum review length :2697\n",
            "Minimum review length :70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDzhfb6lHPSA"
      },
      "source": [
        "max_review_length =500\n",
        "X_train = pad_sequences(X_train,maxlen=max_review_length)\n",
        "X_test = pad_sequences(X_train,maxlen=max_review_length)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dFy4ykXBKKtZ",
        "outputId": "1a8445bf-e265-4ba9-bf78-1fd61898b6c0"
      },
      "source": [
        "\"Input is a sequence of words of max length =max_review_length\"\n",
        "\"Output is in format 0 for negative and 1 from positive\"\n",
        " #creating the model using sequential layer by layer\n",
        "embedding_vector_length =32\n",
        "model = keras.Sequential()\n",
        "model.add(Embedding(top_words,embedding_vector_length,input_length=max_review_length))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "\"\"\"Compile the model by specifying the loss function and optimizer\n",
        "and specifying the appropriate parameters, including at least one metric frequency\"\"\"\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "model.fit(X_train,y_train,validation_data=(X_test,y_test),epochs=30,batch_size=64)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 500, 32)           160000    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 500, 32)           0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 100)               53200     \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 101       \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/30\n",
            "391/391 [==============================] - 305s 773ms/step - loss: 0.5072 - accuracy: 0.7453 - val_loss: 1.1687 - val_accuracy: 0.4982\n",
            "Epoch 2/30\n",
            "391/391 [==============================] - 300s 769ms/step - loss: 0.3366 - accuracy: 0.8588 - val_loss: 1.3646 - val_accuracy: 0.4967\n",
            "Epoch 3/30\n",
            "391/391 [==============================] - 298s 763ms/step - loss: 0.2914 - accuracy: 0.8844 - val_loss: 1.3644 - val_accuracy: 0.4972\n",
            "Epoch 4/30\n",
            "391/391 [==============================] - 300s 769ms/step - loss: 0.2493 - accuracy: 0.9036 - val_loss: 1.5134 - val_accuracy: 0.4967\n",
            "Epoch 5/30\n",
            "391/391 [==============================] - 296s 758ms/step - loss: 0.2312 - accuracy: 0.9120 - val_loss: 1.9447 - val_accuracy: 0.4954\n",
            "Epoch 6/30\n",
            "391/391 [==============================] - 295s 756ms/step - loss: 0.2046 - accuracy: 0.9230 - val_loss: 1.8039 - val_accuracy: 0.4943\n",
            "Epoch 7/30\n",
            "391/391 [==============================] - 293s 751ms/step - loss: 0.2368 - accuracy: 0.9052 - val_loss: 1.7101 - val_accuracy: 0.4956\n",
            "Epoch 8/30\n",
            "391/391 [==============================] - 294s 754ms/step - loss: 0.1883 - accuracy: 0.9285 - val_loss: 2.0384 - val_accuracy: 0.4954\n",
            "Epoch 9/30\n",
            "391/391 [==============================] - 297s 760ms/step - loss: 0.1612 - accuracy: 0.9399 - val_loss: 2.0815 - val_accuracy: 0.4955\n",
            "Epoch 10/30\n",
            "391/391 [==============================] - 300s 768ms/step - loss: 0.1509 - accuracy: 0.9428 - val_loss: 2.0758 - val_accuracy: 0.4985\n",
            "Epoch 11/30\n",
            "391/391 [==============================] - 301s 771ms/step - loss: 0.1412 - accuracy: 0.9479 - val_loss: 2.3880 - val_accuracy: 0.4948\n",
            "Epoch 12/30\n",
            "391/391 [==============================] - 300s 767ms/step - loss: 0.1272 - accuracy: 0.9535 - val_loss: 2.8678 - val_accuracy: 0.4954\n",
            "Epoch 13/30\n",
            "391/391 [==============================] - 300s 769ms/step - loss: 0.1348 - accuracy: 0.9515 - val_loss: 2.7826 - val_accuracy: 0.4970\n",
            "Epoch 14/30\n",
            "391/391 [==============================] - 298s 764ms/step - loss: 0.1103 - accuracy: 0.9606 - val_loss: 2.5021 - val_accuracy: 0.4988\n",
            "Epoch 15/30\n",
            "391/391 [==============================] - 298s 761ms/step - loss: 0.0957 - accuracy: 0.9672 - val_loss: 2.9096 - val_accuracy: 0.4965\n",
            "Epoch 16/30\n",
            "391/391 [==============================] - 298s 763ms/step - loss: 0.0917 - accuracy: 0.9672 - val_loss: 2.7198 - val_accuracy: 0.4950\n",
            "Epoch 17/30\n",
            "391/391 [==============================] - 303s 775ms/step - loss: 0.0946 - accuracy: 0.9669 - val_loss: 2.9933 - val_accuracy: 0.4954\n",
            "Epoch 18/30\n",
            "391/391 [==============================] - 307s 787ms/step - loss: 0.1092 - accuracy: 0.9608 - val_loss: 2.6171 - val_accuracy: 0.4967\n",
            "Epoch 19/30\n",
            "391/391 [==============================] - 298s 763ms/step - loss: 0.0741 - accuracy: 0.9746 - val_loss: 3.2261 - val_accuracy: 0.4966\n",
            "Epoch 20/30\n",
            "391/391 [==============================] - 301s 770ms/step - loss: 0.0771 - accuracy: 0.9737 - val_loss: 3.5068 - val_accuracy: 0.4961\n",
            "Epoch 21/30\n",
            "391/391 [==============================] - 300s 768ms/step - loss: 0.0608 - accuracy: 0.9788 - val_loss: 3.9606 - val_accuracy: 0.4965\n",
            "Epoch 22/30\n",
            "391/391 [==============================] - 306s 784ms/step - loss: 0.0538 - accuracy: 0.9818 - val_loss: 3.5986 - val_accuracy: 0.4960\n",
            "Epoch 23/30\n",
            "130/391 [========>.....................] - ETA: 2:35 - loss: 0.0424 - accuracy: 0.9870"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K7vLepQPMewG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "409949d4-1f82-402e-d7b8-59c9bfa3932b"
      },
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 50.00%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZNOkHuiI0Yo",
        "outputId": "9ae051cd-1b09-4434-e1aa-bae444c6be13"
      },
      "source": [
        "#Run these codes first in order to install the necessary libraries and perform authorization\n",
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 148486 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.26-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.26-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa2YuNIBJaRY"
      },
      "source": [
        "#Mount your Google Drive:\n",
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQ9njsZCJoAs"
      },
      "source": [
        "#After success run Drive FUSE program,creating a directory Sentiment_Analysis and access the drive at /content/drive with using command\n",
        "import os\n",
        "#os.mkdir(\"/content/drive/Sentiment_Analysis\")\n",
        "os.chdir(\"/content/drive/\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImvyjjZqJ9tV"
      },
      "source": [
        "#Append your path\n",
        "import sys\n",
        "sys.path.append('/content/drive/Sentiment_Analysis')\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciVlnCX9KD89",
        "outputId": "d76bf406-1c0d-4bac-a2b1-59a5392fd86b"
      },
      "source": [
        "#Now save the model in required directory\n",
        "model.save('/content/drive/Sentiment_Analysis/sentiment_analysis_model.h5')\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6UmMQsbLAEg",
        "outputId": "2b7a2186-c0e3-4fbe-946e-8e43c7d5fbb9"
      },
      "source": [
        "#Check the content of the directory\n",
        "os.chdir(\"/content/drive/Sentiment_Analysis\")\n",
        "!ls"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentiment_analysis_model.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrzcFaGlLBhV",
        "outputId": "f6e1de53-ba1c-4794-b243-ab0fa7f2f56b"
      },
      "source": [
        "#Code to load the saved model\n",
        "model = load_model('/content/drive/Sentiment_Analysis/sentiment_analysis_model.h5')\n",
        "print(\"Model Loaded\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Loaded\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}